\documentclass{article}[12pt]
\usepackage{fullpage}
\usepackage{multicol}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage[ruled,lined,linesnumbered]{algorithm2e}
%\usepackage{algpseudocode}
\usepackage{multicol}
\usepackage{enumitem}
\usepackage{url}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{hyperref}
%\usepackage{bookmark}

\ifx\solutiontemplate\undefined
\newcommand{\solkeyword}[1]{}
\newcommand{\policy}[1]{#1}
\else
\newcommand{\solkeyword}[1]{#1}
\newcommand{\policy}[1]{}
\fi

\newcommand\encircle[1]{\raisebox{.5pt}{\textcircled{\raisebox{-.9pt} {\footnotesize #1}}} }


\newenvironment{solution}[0]{\vspace{.1in} \textbf{Solution.} \,}{}

\newcommand{\deadline}{11:59pm, 2/4, 2025}

\newcommand{\assigntitle}[1]{{
  \noindent \large \bf
  CS141, Winter 2025,
  Assignment \##1 \hfill Due: {\deadline}\\
  Name: Danny Topete %put in your name here
  \hspace{2.5in}
  Student ID: 862389624 %put in your id here
  \\
  [-.05in]
  \mbox{}\hrulefill \mbox{}\\}}

\begin{document}

\assigntitle{2}{}
\policy{\textbf{Deadline.} The homework is due 11:59pm, Tues 2/4, 2025. You must submit your solutions (in pdf
format generated by LaTeX) via GradeScope. Canvas will not be accepted.}\\
\date{}
\policy{\textbf{Assignment Policy.}
\begin{itemize}
    \item Unless mentioned otherwise, late submission allowed for 20\% penalty for each calendar day.
    \item Assignments should be in pdf format generated by LaTeX
    \item If you are using any external source, you must cite it and clarify what exactly got out of it.
    \item You are expected to understand any source you use and solve problems in your own.
    \item All pages relevant to a question must be assigned on Gradescope. Unassigned pages will not be graded.
\end{itemize}


}

\section{Finding Local Minima (20 points) }


\subsection{Linear Time (5 pts)}
Linear-time algorithm to find a local minimum in an array of size $n$.
Given an array $A$ of size $n$.
\begin{itemize}
  \item int \textbf{localMin}(int A[], int n)
    \begin{itemize}
      \item \textbf{if} (n == 1) \textbf{return} A[0]; // Base case
      \item \textbf{if} (A[0] < A[1]) \textbf{return} A[0]; // Check the first element
      \item \textbf{if} (A[n-1] < A[n-2]) \textbf{return} A[n-1]; // Check the last element
      \item \textbf{for} (int i = 1; i < n-1; i++) // Check the rest of the elements
        \begin{itemize}
          \item \textbf{if} (A[i] < A[i-1] \textbf{AND} A[i] < A[i+1]) \textbf{return} A[i];
        \end{itemize}
    \end{itemize}
  \item This algorithm has a time complexity of $\Theta(n)$
  \begin{itemize}
%    \item Every part of the function is \Theta(1) until the for loop
    \item The For loop runs for $n-2$ iterations (ignoring the base cases, start, and end)
  \end{itemize}
\end{itemize}

\pagebreak

\vspace*{10px}
\subsection{Log Solution (10 pts)}

\begin{itemize}
  \item The algorithm that we will use to find the local minimum is a binary search algorithm.
  \item Since we already know binary search trees are $\log n$ height, we can use this to our advantage.
  \item The algorithm will be $\Theta(\log n)$
  \item The algorithm will be as follows:
  \item int \textbf{localMinBST}(int A[], int low, int high)
    \begin{itemize}
      \item \textbf{if} (low == high) \textbf{return} A[low]; // Base case
      \item int mid = low + (high - low) / 2;
      \item \textbf{if} (A[mid] < A[mid-1] \textbf{AND} A[mid] < A[mid+1]) \textbf{return} A[mid];
      \item \textbf{if} (A[mid-1] < A[mid]) \textbf{return} \textbf{localMinBST}(A, low, mid-1);
      \item \textbf{else} \textbf{return} \textbf{localMinBST}(A, mid+1, high);
    \end{itemize}
  \item int \textbf{localMin}(int A[], int n) \{ \textbf{return} \textbf{localMinBST}(A, 0, n-1); \}
  \item The helper function \textbf{localMinBST}
    will be the recursive function that will find the local minimum.
\end{itemize}

\vspace*{10px}
\subsection{Recurrence (5 pts)}
Justification:
\begin{itemize}
  \item The binary search algorithm divides the array in half each recursive call
  \item The recurrence relation is $T(n) = T(\frac{n}{2}) + 1$
  \item This algorithm is $\Theta(\log n)$ due to the $(\log n)$ height of binary search trees
  \item Then every single action/comparison within the function is constant time
\end{itemize}




\newpage
\section{Solve the Recurrences (15 points)}

\subsection{$T(n) = 3T\left(\frac{n}{2}\right) + \frac{n^2}{\log^2 n}$}

\begin{itemize}
  \item The pattern that this recurrence follows is as this:
  \item Given $k$ = 1
\end{itemize}

\begin{equation*}
  T(n) = 3^{k} T\left(\frac{n}{2^{k}}\right) + 3^{k-1} \frac{(\frac{n}{2^{k-1}})^{2}}{\log^2 (\frac{n}{2^{k-1}})}
  \Rightarrow
%  T(n) = 3^{k} T\left(\frac{n}{2^{k}}\right) + (\frac{3}{4})^{k-1} \frac{(\frac{n}{2^{k-1}})^{2}}{\log^2 (\frac{n}{2^{k-1}})}
  T(n) = 3^{k} T\left(\frac{n}{2^{k}}\right) + (\frac{3}{4})^{k-1} \frac{(n^{2})}{\log^2 (\frac{n}{2^{k-1}})}
\end{equation*}

\begin{itemize}
  \item We can now solve for $k$ given the base case $T(1) = 1$
  \item $T(1)$ = $\frac{n}{2^{k}}$ = 1
  \item $n$ = $2^{k}$
  \item $k$ = $\log n$
  \item Now to solve the recurrence we can plug in $k$ = $\log n$
\end{itemize}

\begin{equation*}
  \sum_{k=1}^{\log n} (\frac{3}{4})^{k-1} \frac{(n^{2})}{\log^2 (\frac{n}{2^{k-1}})}
  \Rightarrow
  n^{2} \sum_{k=1}^{\log n} \frac{(3/4)^{k}}{\log^2 (\frac{n}{2^{k-1}})}
  \Rightarrow
  n^{2} \sum_{k=1}^{\log n} \frac{(3/4)^{k}}{\log^2 n}
\end{equation*}

\begin{itemize}
  \item This summation would converge to:
\end{itemize}

\begin{equation*}
  \frac{n^2}{\log^2 n} \sum_{k=1}^{\log n} (3/4)^{k}
  \Rightarrow
  \Theta(\frac{n^2}{\log^2 n})
\end{equation*}


\pagebreak

\vspace*{10px}
\subsection{$T(n) = T\left(\frac{n}{4}\right) + T\left(\frac{3n}{4}\right) + n \log n$}
\begin{itemize}
  \item The pattern that this recurrence follows is as this:
  \item Given $k$ = 1
\end{itemize}

\begin{equation*}
  T(n) = T(\frac{n}{4^{k}}) + T(\frac{3^{k}n}{4^{k}}) + \frac{n \log n}{4^{k}} + \frac{3n (\log 3n - \log 3^{k})}{4^{k}}
\end{equation*}
\begin{itemize}
  \item We can now solve for $k$ given the base case $T(1) = 1$
  \item Using the base case of $T(1)=1$ we can solve for $k$
  \item $T(1)$ = $\frac{n}{4^{k}}$ = 1
  \item $n$ = $4^{k}$
  \item $k$ = $\log n$
  \item Now to solve the recurrence we can plug in $k$ = $\log n$
  \item $T(n)$ = $T(1) + T(3n) + n \log n$
  \item $T(n)$ = $1 + T(3n) + n \log n$
  \item Given that we have a $k$ = $\log n$ we can solve for the recurrence
\end{itemize}
\begin{equation*}
  \sum_{k=0}^{\log n} 3^{k} + n \log n
  \Rightarrow 3^{\log n} + n \log n
  \Rightarrow n^{\log 3} + n \log n
  \Rightarrow \sum_{k=0}^{\log n} n \log n
\end{equation*}
\begin{equation*}
  n \log n \log n
  \Rightarrow \Theta(n \log^{2} n)
\end{equation*}
\begin{itemize}
  \item After focusing on the highest growing part of the summation
    we can conclude that this recurrence is $\Theta(n \log^{2} n)$.
\end{itemize}


\pagebreak

\vspace*{10px}
\subsection{$T(n) = 3T\left(\frac{n}{2}\right) + n^2$}
\begin{itemize}
  \item The pattern that this recurrence follows is as this (in a summation form):
  \item Given $k$ = 1
\end{itemize}

\begin{equation*}
  T(n) = 3^{k} T\left(\frac{n}{2^{k}}\right) + 3^{k-1} (\frac{n}{2^{k-1}})^{2}
  \Rightarrow
  T(n) = 3^{k} T\left(\frac{n}{2^{k}}\right) + 3^{k-1} (\frac{n^{2}}{4^{k-1}}) \\
\end{equation*}
\begin{equation*}
  \Rightarrow
  T(n) = 3^{k} T\left(\frac{n}{2^{k}}\right) + (\frac{3}{4})^{k-1} (n^{2})
\end{equation*}

\begin{itemize}
  \item We can now solve for $k$ given the base case $T(1) = 1$
  \item $T(1)$ = $\frac{n}{2^{k}}$ = 1
  \item $n$ = $2^{k}$
  \item $k$ = $\log n$
  \item Now to solve the recurrence we can plug in $k$ = $\log n$
  \item $T(n)$ = $3^{\log n} T(1) + (\frac{3}{4})^{\log n - 1} n^{2}$
  \item $T(n)$ = $n^{\log 3} + (\frac{3}{4})^{\log n - 1} n^{2}$
  \item $T(n)$ = $n^{\log 3} + (\frac{3}{4})^{\log n} n^{2}$
  \item Looking at this equation we can see that the second term is $O(n^{2})$
  \item Therefore the overall time complexity is $O(n^{2})$
\end{itemize}

\newpage

\section{Significant Inversion (15 points)}

\subsection{Algorithm (10 pts)}


% Comment to compile
%\begin{algorithm}[H]
%  \If {low $\geq$ high} {%
%  \Return 0\;
%}
%\caption{CountSignificantInversions(X, low, high)}{
%mid = (low + high) / 2\;
%count = CountSI(X, low, mid) + CountSI(X, mid+1, high)\;
%j = mid+1\;
%\For {i = low to mid} {%
%  \While {j $\leq$ high \textbf{AND} X[i] $\geq$ 2 \cdot X[j]} {%
%    ++j\;
%  }%
%  count += j - (mid+1)\;
%}
%Merge(X, low, mid, high)\;
%Return count\;
%}
%\end{algorithm}
\begin{itemize}
  \item Function CountSI(X, low, high)
    \begin{itemize}
      \item \textbf{if} (low $\geq$ high) \textbf{return} 0;
      \item mid = (low + high) / 2;
      \item count = CountSI(X, low, mid) + CountSI(X, mid+1, high);
      \item j = mid+1;
      \item \textbf{for} (i = low to mid)
        \begin{itemize}
          \item \textbf{while} (j $\leq$ high \textbf{AND} X[i] $\geq$ 2 $\cdot$ X[j])
        \begin{itemize}
          \item ++j;
        \end{itemize}
          \item count += j - (mid+1);
        \end{itemize}
      \item Merge(X, low, mid, high);
      \item \textbf{return} count;
\end{itemize}
\end{itemize}

\vspace*{10px}
\subsection{Recurrence \& Time Complexity (5 pts)}
\begin{itemize}
  \item The recurrence relation for this algorithm is $T(n) = 2T(\frac{n}{2}) + O(n)$
  \item The algorithm is called twice within the code and the 
    array is split in half for each call. Making the algorithm 
    2T($\frac{n}{2}$)
  \item The $O(n)$ comes from the for loop that iterates through the array
  \item Using master's theorem,
    $n^{\log_{2} 2}$ = n$^{1}$ = n.
    Which is equal to the $O(n)$ in the recurrence relation
  \item This algorithm is $\Theta(n \log n)$
\end{itemize}

\newpage
\section{Data Recovery (15 points)}
\subsection{Algorithm (10 pts}

\begin{itemize}
  \item \textbf{Objective}: Look for the longest common sequence
    using divide and conquer 
\end{itemize}

function \textbf{commonSequence}(string s1, string s2)
\begin{itemize}
  \item \textbf{if} (s1.length() == 0 \textbf{OR} s2.length() == 0) \textbf{return} "";
  \item minLength = min(s1.length(), s2.length());
  \item result = ""
  \item \textbf{for} i = 0 to minLength-1
    \begin{itemize}
      \item \textbf{if} (s1[i] == s2[i]): result += s1[i];
      \item else \textbf{break};
    \end{itemize}
  \item return result
\end{itemize}

function \textbf{longestCommonSequence}(string s1, string s2, int low, int high)
\begin{itemize}
  \item if low == high \textbf{return} s1[low]; $//$ base case
  \item mid = (low + high) / 2;
  \item left = \textbf{longestCommonSequence}(s1, s2, low, mid);
  \item right = \textbf{longestCommonSequence}(s1, s2, mid+1, high);

  \item $//$ Merging step of the common prefixes
  \item \textbf{return} \textbf{commonSequence}(left, right);
\end{itemize}

\vspace*{10px}
\subsection{Recurrence \& Time Complexity (5 pts)}
\begin{itemize}
  \item The recurrence relation for this 
    algorithm is $T(n) = 2T(\frac{n}{2}) + O(m)$
    \begin{itemize}
      \item The algorithm is called twice within the code
      \item The array is split in half for each call
      \item Making the branches 2T($\frac{n}{2}$), which would lead
        to $n^{\log_{2} 2}$ = n$^{1}$ = n
      \item The merge step is $\Theta(m)$, meaning the leaves would be $\Theta(m)$
      \item Combining the two we get the time complexity of $\Theta(n \cdot m)$
    \end{itemize}
\end{itemize}

\newpage
\section{Modified Merge Sort (20 pts)}

\vspace*{10px}
\subsection{Recurrence Relation (10 pts)}
\begin{itemize}
  \item The recurrence relation for 
    this algorithm is $T(n) = 4T(\frac{n}{4}) + \Theta(n)$
    \begin{itemize}
      \item We call the algorithm 4 times with $\frac{n}{4}$ elements
      \item The $\Theta(n)$ comes from the merge step
      \item Each merge step is $\Theta(n)$
      \item Typical merge sort would have $T(n) = 2T(\frac{n}{2}) + \Theta(n)$
      \item Although this algorithm has 4 recursive calls,
        the merge step is the same
    \end{itemize}
\end{itemize}

\vspace*{10px}
\subsection{Solve the Recurrence (10 pts)}

\begin{itemize}
  \item Using master's theorem, we can solve the recurrence
  %\item For the recurrence $T(n) = aT(\frac{n}{b}) + f(n)$ \Rightarrow $T(n) = 4T(\frac{n}{4}) + \Theta(n)$
  \item a = 4, b = 4, f(n) = n
  \item $n^{\log_{4} 4}$ = $n^{1}$ = n
  \item Since $f(n) = \Theta(n)$, we can conclude that
    the time complexity of this algorithm is $\Theta(n \log n)$
\end{itemize}

\vspace*{10px}
\subsection{Compare (5 pts)}
\begin{itemize}
  \item The time complexity of the ModifiedMergeSort is $\Theta(n \log n)$
  \item The time complexity of the MergeSort is $\Theta(n \log n)$
  \item Both algorithms have the same time complexity
  \item The difference between the two algorithms is the number of recursive calls.
    Which is offset since they make an equal amount of splits as they do calls.
  \item When you have the same amount of splits as calls, the time complexity is the same
\end{itemize}

\newpage
\section{Molecular Matching (15 points)}
Micheal runs a drug discovery start-up, he hopes to one day make a breakthrough. Ziyang has a 
machine learning model that represents all possible molecules in a 2D coordinate system.
Micheal figures that if he tries two molecules very close in the coordinate space, he'll waste time.
He wants to find teh closest two moledcules and remove one of them.

Formally given a set of points {$P_1, P_2, ... , P_n$} where each point is a 2D coordinate,
is represented by $P_i = (x_i, y_i)$.

\begin{equation*}
  d(P_i, P_j) = \sqrt{(x_i - x_j)^2 + (y_i - y_j)^2}
\end{equation*}

Write an algorithm to return Euclidean distances between the two closest points in your data set.
\begin{itemize}
  \item Must be $O(n \log n)$
  \item Assume no two points have the exact same coordinates
\end{itemize}

\begin{itemize}
  \item \textbf{Algorithm}:
    \begin{itemize}
      \item \textbf{Objective}: Find the closest two points in the data set
      \item \textbf{Input}: Set of points {$P_1, P_2, ... , P_n$}
      \item \textbf{Output}: Euclidean distance between the two closest points
      \item \textbf{Method}:
        \begin{itemize}
          \item Sort the points by their x-coordinate
          \item Divide the points into two halves
          \item Recursively find the smallest distances in each half
          \item Find the smallest distance between the two halves
          \item Return the smallest distance
        \end{itemize}
    \end{itemize}
\end{itemize}

\begin{itemize}
  \item \textbf{Recurrence Relation}:
    \begin{itemize}
      \item $T(n) = 2T(\frac{n}{2}) + \Theta(n \log n)$
      \item The $\Theta(n \log n)$ comes from the merge step
      \item The merge step is $\Theta(n \log n)$
      \item The algorithm is called twice with $\frac{n}{2}$ elements
    \end{itemize}
\end{itemize}

\begin{itemize}
  \item \textbf{Solve the Recurrence}:
    \begin{itemize}
      \item Using master's theorem, we can solve the recurrence
  %    \item For the recurrence $T(n) = aT(\frac{n}{b}) + f(n)$ \Rightarrow $T(n) = 2T(\frac{n}{2}) + \Theta(n \log n)$
      \item a = 2, b = 2, f(n) = n
      \item $n^{\log_{2} 2}$ = $n^{1}$ = n
      \item Since $f(n) = \Theta(n)$, we can conclude that
        the time complexity of this algorithm is $\Theta(n \log n)$
    \end{itemize}
  \item \textbf{euclideanDistance}(Point p1,Point p2 )
    \begin{itemize}
      \item \textbf{return} sqrt( (p1.x - p2.x)**2 + (p1.y - p2.y)**2 )
    \end{itemize}
\end{itemize}

\pagebreak

\begin{itemize}
  \item \textbf{ClosestPoints} (Points P[][], int n)
    \begin{itemize}
      \item sort(P, n) $//$ Sort points by x-coordinate
      \item \textbf{return} ClosestPointsRec(P, 0 ,n) $//$ Holds points, start, and end
    \end{itemize}
  \item $//$ Function to find the smallest distance in the strip area
  \item \textbf{stripClose}(strip, dist)
    \begin{itemize}
      \item minDist = dist
      \item sort(strip, strip.size())
      \item \textbf{for} i = 0 to strip.size()
        \begin{itemize}
          \item \textbf{for} j = i+1 to strip.size() \textbf{AND} (strip[j].y - strip[i].y) $<$ min
        \begin{itemize}
          \item minDist = min(dist, euclideanDistance(strip[i], strip[j]))
        \end{itemize}
        \end{itemize}
      \item \textbf{return} minDist
    \end{itemize}

  \item $//$ NOTE: Brute force method is only ever used when the data set is small
  \item \textbf{bruteForce}(Points P[], int start, int end)
    \begin{itemize}
      \item min = $\infty$
      \item \textbf{for} i = start to end
        \begin{itemize}
          \item \textbf{for} j = i+1 to end
            \begin{itemize}
              \item min = min(min, euclideanDistance(P[i], P[j]))
            \end{itemize}
        \end{itemize}
      \item \textbf{return} min
    \end{itemize}

  \item $//$ Recursive function to find the smallest distance
  \item \textbf{ClosestPointsRec} (Points P[], int start, int end)
    \begin{itemize}
      \item \textbf{if} ((end - start) $\leq$ 3) \textbf{return} bruteForce(P, start, end)
      \item mid = (start + (start - end)) /  2
      \item Point midPoint = P[mid]
      \item double distLeft = ClosestPointsRec(P, left, mid)
      \item double distRight = ClosestPointsRec(P, mid + 1, end)
      \item double dist = min(distLeft, distRight)

      \item $//$ Find the smallest distance between the two halves.
        Declare this new array.
      \item Point strip[]

      \item \textbf{for} i = start to end 
        \begin{itemize}
          \item \textbf{if} (abs(P[i].x - midPoint.x) < d)
            \begin{itemize}
              \item strip.pushBack(P[i])
            \end{itemize}
        \end{itemize}
      \item \textbf{return} min(dist, stripClose(strip, j, dist))
    \end{itemize}
\end{itemize}


\end{document}
